{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FifaRankingResults3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoESJhfcDfJrVPqCgVT05s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mjcherono/IP-Week-6-FifaRanking/blob/main/FifaRankingResults3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absyRRCwgu_X"
      },
      "source": [
        "###Importing Libraries and Loading the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUs7IfXGUa9f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGW34xFGUj72"
      },
      "source": [
        "ranking = pd.read_csv('/content/fifa_ranking.csv')\n",
        "results = pd.read_csv('/content/results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L01-rAcVVNt"
      },
      "source": [
        "#checking on head\n",
        "ranking.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf1tHtMpVXm-"
      },
      "source": [
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYvi4GsachHG"
      },
      "source": [
        "# Previewing the bottom of our dataset\n",
        "print(ranking.tail())\n",
        "print(results.tail())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDt3aq0qcZRX"
      },
      "source": [
        "# Determining the no. of records in our dataset\n",
        "print(ranking.shape)\n",
        "print(results.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AQc-f6iceiZ"
      },
      "source": [
        "# Checking whether each column has an appropriate datatype\n",
        "print(results.dtypes)\n",
        "print(ranking.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRv3lxulclsw"
      },
      "source": [
        "#summary of datasets\n",
        "print(ranking.describe())\n",
        "print(results.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiquv7vjVorW"
      },
      "source": [
        "#changing date to datetime\n",
        "\n",
        "results['date'] = pd.to_datetime(results['date'])\n",
        "ranking['rank_date'] = pd.to_datetime(ranking['rank_date'])\n",
        "\n",
        "#splitting year and month on dates\n",
        "results['year'] = results.date.dt.year\n",
        "results['month'] = results.date.dt.month\n",
        "\n",
        "ranking['year'] = ranking.rank_date.dt.year\n",
        "ranking['month'] = ranking.rank_date.dt.month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX7y1U2eVOCy"
      },
      "source": [
        "#merging the datasets\n",
        "final_results = pd.merge(results, ranking, how = 'left', left_on = ['year', 'month'], right_on = ['year', 'month'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHfBUROqVwez"
      },
      "source": [
        "final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5tVUB2dhmpq"
      },
      "source": [
        "###Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQvcQ32CVyRS"
      },
      "source": [
        "#checking for null values\n",
        "final_results.isnull().sum()\n",
        "\n",
        "#dropping null values\n",
        "final_results.dropna()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS5WVPktWayZ"
      },
      "source": [
        "final_results.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NaXHdqcXn7Z"
      },
      "source": [
        "\n",
        "#Checking out for Duplicates\n",
        "final_results.duplicated().sum()\n",
        "\n",
        "final_results.drop_duplicates(inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CwSxsGWYGQe"
      },
      "source": [
        "final_results.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_1msHLnXsHW"
      },
      "source": [
        "#dropping irrelevant columns\n",
        "\n",
        "final_results = final_results[['rank','country_full','home_team','away_team','home_score','away_score','tournament','year','month']]\n",
        "final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPdOoKhpYfTB"
      },
      "source": [
        "#creating a function to determine the status of a game\n",
        "def status_hometeam(home_score,away_score):\n",
        "  if home_score > away_score:\n",
        "    return 'Win'\n",
        "  elif home_score < away_score:\n",
        "    return 'Lose'\n",
        "  else:\n",
        "    return 'Draw'\n",
        "\n",
        "#creating status column\n",
        "final_results['status']=final_results.apply(lambda x: status_hometeam(x['home_score'],x['away_score']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRkWhh9LYplw"
      },
      "source": [
        "final_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEh_OObZ5UI"
      },
      "source": [
        "###Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5kuc96XZ-4k"
      },
      "source": [
        "####Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4WtVHvFaDCa"
      },
      "source": [
        "#####Distribution of home scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pGZ1mb7Z1wj"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.distplot(final_results.home_score , kde=True)\n",
        "plt.title('Histogram of Home score Distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkkQ7uCWadga"
      },
      "source": [
        "#line plot fr home score\n",
        "\n",
        "final_results['home_score'].value_counts().sort_index().plot.line()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O3KrsWVaLXO"
      },
      "source": [
        "#####Distibution of Away scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZqEaXalaJ_K"
      },
      "source": [
        "sns.distplot(final_results.away_score , kde=True)\n",
        "plt.title('Histogram of Away score Distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSnzD8FqaUbJ"
      },
      "source": [
        "#label encode the categorical columns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "final_results['tournament'] = le.fit_transform(final_results['tournament'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtZoUaxak3a"
      },
      "source": [
        "####Binary Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAbY3wJBaodi"
      },
      "source": [
        "##Pairplot to heck for corelation\n",
        "#sns.pairplot(final_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG0ldV_5ataq"
      },
      "source": [
        "#heat map for correlation purposes\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "fr_corr = final_results.corr()\n",
        "sns.heatmap(fr_corr, \n",
        "            xticklabels = fr_corr.columns.values,\n",
        "            yticklabels = fr_corr.columns.values,\n",
        "            annot = True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJoVhaA5bM9n"
      },
      "source": [
        "#Boxplot representation of home scores over the years\n",
        "\n",
        "sns.boxplot(x=\"home_score\", y=\"year\", data=final_results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa3eXQAOdhzJ"
      },
      "source": [
        "#Boxplot representation of away scores over the years\n",
        "\n",
        "sns.boxplot(x=\"away_score\", y=\"year\", data=final_results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0YXh92mfQym"
      },
      "source": [
        "final_results.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5__am6DfBVw"
      },
      "source": [
        "final_results['rank'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pShggvaffmM"
      },
      "source": [
        "final_results['home_team'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb9Pli3ifsea"
      },
      "source": [
        "final_results['away_team'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wAi7k7Ifub4"
      },
      "source": [
        "final_results['home_score'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHUScz3CfvQd"
      },
      "source": [
        "final_results['away_score'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6YMhqX9f2NP"
      },
      "source": [
        "final_results['tournament'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJqpmr0Xf6EQ"
      },
      "source": [
        "\n",
        "final_results['status'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLl7xalUierK"
      },
      "source": [
        "#####Average goals per year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw1uYJMegLs2"
      },
      "source": [
        "#Home scores\n",
        "\n",
        "home_goals = final_results.groupby('year')['home_score'].mean().reindex()\n",
        "sns.lineplot(data = home_goals )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwwzGLimiw2S"
      },
      "source": [
        "#Away scores\n",
        "\n",
        "away_goals = final_results.groupby('year')['away_score'].mean().reindex()\n",
        "sns.lineplot(data = away_goals )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksyDVi2lnHOJ"
      },
      "source": [
        "#####Distribution of ranks over the number of scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5I-OlbkWid"
      },
      "source": [
        "final_results.plot.scatter(x='home_score', y='rank')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e95c-Pfzploa"
      },
      "source": [
        "###Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78DLhCiVuam-"
      },
      "source": [
        "final_results.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWG-uLTouk3u"
      },
      "source": [
        "#dropping country full and month\n",
        "\n",
        "final_results.drop(['country_full','month'],inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGuvSfA_0Md2"
      },
      "source": [
        "final_results.drop(['year'],inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJDb20Kcu43f"
      },
      "source": [
        "final_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP-37Posu_uX"
      },
      "source": [
        "####Detecting multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOpCAVdXvDZE"
      },
      "source": [
        "#We'll check for collinearity in independent variables\n",
        "\n",
        "correlations = final_results.drop(['home_score'], axis=1)\n",
        "correlations.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qlgySNsynbz"
      },
      "source": [
        "#Computing VIF Scores\n",
        "\n",
        "#pd.DataFrame(np.linalg.inv(correlations.values), index = correlations.index, columns = correlations.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ymgL7Q2OCo"
      },
      "source": [
        "final_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbtC5lGmpuCO"
      },
      "source": [
        "####Model 1: Predict how many goals the home team scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXoMHMTMoj8F"
      },
      "source": [
        "#creating and training our polynomial model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "X = final_results[['rank','tournament']]\n",
        "y = final_results['home_score']\n",
        "\n",
        "#split to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 25)\n",
        "\n",
        "#fit a polynomial regression\n",
        "poly = PolynomialFeatures(degree = 6)\n",
        "poly.fit_transform(X_train)\n",
        "\n",
        "#training our model\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_train,y_train)\n",
        "\n",
        "#making predictions\n",
        "y_pred = poly_reg.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "#using rmse to measure the accuracy\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlEb68lpqEO6"
      },
      "source": [
        "final_results.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bundnayaqWQN"
      },
      "source": [
        "####Model 2: Predict how many goals the away team scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrCX_wcFqIA3"
      },
      "source": [
        "#creating and training our polynomial model\n",
        "#for the second model we use away scores\n",
        "\n",
        "X = final_results[['rank','tournament']]\n",
        "y = final_results['away_score']\n",
        "\n",
        "#split to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 25)\n",
        "\n",
        "#fit a polynomial regression\n",
        "poly = PolynomialFeatures(degree = 2)\n",
        "poly.fit_transform(X_train)\n",
        "\n",
        "#training our model\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_train,y_train)\n",
        "\n",
        "#making predictions\n",
        "y_pred = poly_reg.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "#using rmse to measure the accuracy\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8lk2gK29HI"
      },
      "source": [
        "#####The lower the value of RMSE the better the model.Hence this model's performance is fairly good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x44FFCg6R1Yg"
      },
      "source": [
        "####Using Residual Plots to check on the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0kOGBWJjsk"
      },
      "source": [
        "#Residual = test value - predicted value\n",
        "\n",
        "residuals = np.subtract(y_pred, y_test)\n",
        "\n",
        "#describe our residual:\n",
        "print(pd.DataFrame(residuals).describe())\n",
        "\n",
        "print(residuals.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoc_793qbktF"
      },
      "source": [
        "######Our residual mean is close to 0 meaning our prediction is fairly correct, though slightly overestimating chances by close to ; 0.13%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5c0xCelcC0k"
      },
      "source": [
        "######Residual plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyjhSfSQcGGh"
      },
      "source": [
        "plt.scatter(y_pred, residuals, color='black')\n",
        "plt.ylabel('residual')\n",
        "plt.xlabel('fitted values')\n",
        "plt.axhline(y= residuals.mean(), color='red', linewidth=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSIgRaRgcWyx"
      },
      "source": [
        "######Our residuals are centered arount the 0 mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOieoAhncmLt"
      },
      "source": [
        "####Heteroskedasticity Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0sK5ZXmcvmw"
      },
      "source": [
        "###### The test establishes a null hypothesis that the variance is equal for all our data points and the alternative hypothesis that the variance is different for atleast one pair of datapoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAXFgwrxcr-o"
      },
      "source": [
        "#finding the p value\n",
        "import scipy as sp\n",
        "\n",
        "test_result, p_value = sp.stats.bartlett(y_pred, residuals)\n",
        "\n",
        "#finding the critical value of the chi squared distribution\n",
        "degree_of_freedom = len(y_pred)-1\n",
        "probability = 1 - p_value\n",
        "\n",
        "critical_value = sp.stats.chi2.ppf(probability, degree_of_freedom)\n",
        "print(critical_value)\n",
        "\n",
        "#if test_result > critical_value we reject the null hypothesis\n",
        "#\n",
        "if (test_result > critical_value):\n",
        "  print('the variances are unequal, and the model should be reassessed')\n",
        "else:\n",
        "  print('the variances are homogeneous!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9wHSKAj3dnq"
      },
      "source": [
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAFUp6tJqeCk"
      },
      "source": [
        "#dataset\n",
        "final_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12PKifQq3-tw"
      },
      "source": [
        "#Checking that our target variable is binary\n",
        "\n",
        "sns.countplot(x='status',data=final_results, palette='hls')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2A_ytWa4IL7"
      },
      "source": [
        "#Converting our categorical variable to dummy indicators\n",
        "#final_results['status']  = pd.get_dummies(final_results['status'],drop_first=False)\n",
        "#final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etAbl-fu8YBd"
      },
      "source": [
        "final_results.drop(['home_team','away_team'],inplace=True , axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmr_zye978Eb"
      },
      "source": [
        "final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqwp2VAX8Di4",
        "outputId": "1a4c4b20-03b2-4a64-c0e4-029658da0919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#splitting the data into features and target\n",
        "\n",
        "X = final_results.drop(\"status\",axis=1)\n",
        "y = final_results[\"status\"]\n",
        "\n",
        "#\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "\n",
        "#splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=20)\n",
        "\n",
        "#creating an object of the model\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "#making y predictions\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "#evaluating the model using a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[141586,      0,      0],\n",
              "       [     0, 164244,      0],\n",
              "       [     0,      0, 294656]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQXsXHzbEm2v"
      },
      "source": [
        "####Hyperparameter tuning for logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97n2OZsFKUo"
      },
      "source": [
        "#####using gridsearch cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAK72EaS-5e2",
        "outputId": "56ad92fa-e383-414e-9a99-a5b9a7ca77a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating regularization penalty space\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# Creating regularization hyperparameter space\n",
        "C = np.logspace(0, 5, 10)\n",
        "\n",
        "# Creating hyperparameter options\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "#grid search using 5-fold cross validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(logreg, hyperparameters, cv=5, verbose=0)\n",
        "\n",
        "#fitting\n",
        "best_model = clf.fit(X, y)\n",
        "\n",
        "#checking on the hyperparameters\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwKkpipNFpkC",
        "outputId": "3982b88a-2dc4-4f90-b6c7-7de02813416c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# Predicting target vector\n",
        "best_model.predict(X)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-7a40d1c579c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predicting target vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPdPSeMKHpi5"
      },
      "source": [
        "###Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnDFBbNcH5zg"
      },
      "source": [
        "#####Logistic regression as a model performed well in the prediction of which team won,lost or had a draw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhWdKYlCIJfi"
      },
      "source": [
        "######The dataset provided for rankings had no data before 1993, therefore was a little insufficient in training the model for better performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7E83H8GHrRU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}